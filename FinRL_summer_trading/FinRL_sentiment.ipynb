{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_PortfolioAllocation_NeurIPS_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNmvYN9YbU4B"
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntfTb0e2bU4C",
    "outputId": "6dd3eee3-d5b4-4a17-f52f-61a3953092ef",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "from datetime import datetime\n",
    "from Data_processor import YahooFinanceProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read sentiment data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tic</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10905</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>wmt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10906</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>wmt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10907</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>wmt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>wmt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10909</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>wmt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10910 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time   tic  value\n",
       "0      2020-01-01  aapl    0.0\n",
       "1      2020-01-02  aapl    0.0\n",
       "2      2020-01-03  aapl    0.0\n",
       "3      2020-01-04  aapl    0.0\n",
       "4      2020-01-05  aapl    0.0\n",
       "...           ...   ...    ...\n",
       "10905  2022-12-27   wmt    0.0\n",
       "10906  2022-12-28   wmt    0.0\n",
       "10907  2022-12-29   wmt    0.0\n",
       "10908  2022-12-30   wmt    0.0\n",
       "10909  2022-12-31   wmt    0.0\n",
       "\n",
       "[10910 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score_df = pd.read_csv(\"../sentiment_score.csv\")\n",
    "sentiment_score_df = sentiment_score_df.rename({\"datetime\":\"time\"},axis=1)\n",
    "sentiment_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slBria_QbU4F"
   },
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定資料日期範圍\n",
    "TRAIN_START_DATE = \"2020-01-01\"\n",
    "TRAIN_END_DATE = \"2021-12-31\"\n",
    "\n",
    "TEST_START_DATE = \"2022-01-01\"\n",
    "TEST_END_DATE = \"2022-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_array(filtered_sentiment_score_df):\n",
    "    unique_ticker = filtered_sentiment_score_df.tic.unique() \n",
    "    if_first_time = True\n",
    "    for tic in unique_ticker:\n",
    "        if if_first_time:\n",
    "            score_array = filtered_sentiment_score_df[filtered_sentiment_score_df.tic == tic][[\"value\"]].values\n",
    "            # price_ary = df[df.tic==tic]['close'].values\n",
    "            if_first_time = False\n",
    "        else:\n",
    "            score_array = np.hstack([score_array, filtered_sentiment_score_df[filtered_sentiment_score_df.tic == tic][[\"value\"]].values])\n",
    "    return score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEwzMkFHbU4G",
    "outputId": "4745f4cc-3e6b-483f-92dc-a3ecae51d69c",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (5040, 9)\n",
      "Clean data for aapl\n",
      "Data clean for aapl is finished.\n",
      "Clean data for dis\n",
      "Data clean for dis is finished.\n",
      "Clean data for jnj\n",
      "Data clean for jnj is finished.\n",
      "Clean data for jpm\n",
      "Data clean for jpm is finished.\n",
      "Clean data for mcd\n",
      "Data clean for mcd is finished.\n",
      "Clean data for nke\n",
      "Data clean for nke is finished.\n",
      "Clean data for pg\n",
      "Data clean for pg is finished.\n",
      "Clean data for unh\n",
      "Data clean for unh is finished.\n",
      "Clean data for vz\n",
      "Data clean for vz is finished.\n",
      "Clean data for wmt\n",
      "Data clean for wmt is finished.\n",
      "Data clean all finished!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (2510, 9)\n",
      "Clean data for aapl\n",
      "Data clean for aapl is finished.\n",
      "Clean data for dis\n",
      "Data clean for dis is finished.\n",
      "Clean data for jnj\n",
      "Data clean for jnj is finished.\n",
      "Clean data for jpm\n",
      "Data clean for jpm is finished.\n",
      "Clean data for mcd\n",
      "Data clean for mcd is finished.\n",
      "Clean data for nke\n",
      "Data clean for nke is finished.\n",
      "Clean data for pg\n",
      "Data clean for pg is finished.\n",
      "Clean data for unh\n",
      "Data clean for unh is finished.\n",
      "Clean data for vz\n",
      "Data clean for vz is finished.\n",
      "Clean data for wmt\n",
      "Data clean for wmt is finished.\n",
      "Data clean all finished!\n",
      "['aapl' 'dis' 'jnj' 'jpm' 'mcd' 'nke' 'pg' 'unh' 'vz' 'wmt']\n",
      "Successfully transformed into array\n",
      "['aapl' 'dis' 'jnj' 'jpm' 'mcd' 'nke' 'pg' 'unh' 'vz' 'wmt']\n",
      "Successfully transformed into array\n",
      "=============\n",
      "price_array_train:  (504, 10)\n",
      "tech_array_train:  (504, 70)\n",
      "turbulence_array_train:  (0,)\n",
      "aug_state_array_train:  (504, 10)\n",
      "-----------\n",
      "price_array_test:  (251, 10)\n",
      "tech_array_test:  (251, 70)\n",
      "turbulence_array_test:  (0,)\n",
      "aug_state_array_test:  (251, 10)\n"
     ]
    }
   ],
   "source": [
    "# 資料下載與前處理(只包含training範圍的資料)\n",
    "\n",
    "# 股票代碼與技術指標的list\n",
    "ticker_list = ['jpm','mcd','wmt','pg','unh','aapl','nke','vz','dis','jnj']\n",
    "\n",
    "# ticker_list =['VTV','VUG','VIG','USMV','QUAL']\n",
    "tech_list = []\n",
    "\n",
    "# 技術指標與VIX的開關，如果不想加就設定為False\n",
    "if_vix = False\n",
    "if_tech = True\n",
    "\n",
    "# 下載並清洗資料\n",
    "DP = YahooFinanceProcessor()\n",
    "train_data = DP.download_data(start_date = TRAIN_START_DATE,end_date = TRAIN_END_DATE,ticker_list = ticker_list, time_interval='1D')\n",
    "train_data = DP.clean_data(train_data)\n",
    "test_data = DP.download_data(start_date = TEST_START_DATE,end_date = TEST_END_DATE,ticker_list = ticker_list, time_interval='1D')\n",
    "test_data = DP.clean_data(test_data)\n",
    "\n",
    "# 加入技術指標和恐慌指數(如果有的話)\n",
    "if if_tech:\n",
    "    tech_list = ['close_30_sma','close_60_sma','macd','boll_ub','boll_lb','dx_30','rsi_30']\n",
    "    train_data = DP.add_technical_indicator(train_data, tech_list)\n",
    "    test_data = DP.add_technical_indicator(test_data, tech_list)\n",
    "    \n",
    "if if_vix:\n",
    "    train_data = DP.add_vix(train_data)\n",
    "    test_data = DP.add_vix(test_data)\n",
    "    \n",
    "# DataFrame轉成np.array\n",
    "price_array_train, tech_array_train, turbulence_array_train = DP.df_to_array(train_data,tech_list, if_vix, if_tech)\n",
    "price_array_test, tech_array_test, turbulence_array_test = DP.df_to_array(test_data,tech_list, if_vix, if_tech)\n",
    "\n",
    "# 加入額外的state資訊 ( RN embedding )\n",
    "train_filtered_sentiment_score_df = train_data.loc[:,['time','tic']].merge(sentiment_score_df,on=[\"time\",\"tic\"],how=\"left\")\n",
    "train_filtered_sentiment_score_df = train_filtered_sentiment_score_df.fillna(0).sort_values(by=[\"time\", \"tic\"]).reset_index(drop=True)\n",
    "test_filtered_sentiment_score_df = test_data.loc[:,['time','tic']].merge(sentiment_score_df,on=[\"time\",\"tic\"],how=\"left\")\n",
    "test_filtered_sentiment_score_df = test_filtered_sentiment_score_df.fillna(0).sort_values(by=[\"time\", \"tic\"]).reset_index(drop=True)\n",
    "aug_state_array_train = get_score_array(train_filtered_sentiment_score_df)\n",
    "aug_state_array_test =get_score_array(test_filtered_sentiment_score_df)\n",
    "# aug_state_array_train = np.zeros((0,0))\n",
    "# aug_state_array_test = np.zeros((0,0))\n",
    "# aug_state_array = np.zeros((price_array.shape[0],11,8)) # (754,11,8)\n",
    "\n",
    "\n",
    "\n",
    "# 印一下形狀\n",
    "print('=============')\n",
    "print('price_array_train: ',price_array_train.shape)\n",
    "print('tech_array_train: ',tech_array_train.shape)\n",
    "print('turbulence_array_train: ',turbulence_array_train.shape)\n",
    "print('aug_state_array_train: ',aug_state_array_train.shape)\n",
    "print('-----------')\n",
    "print('price_array_test: ',price_array_test.shape)\n",
    "print('tech_array_test: ',tech_array_test.shape)\n",
    "print('turbulence_array_test: ',turbulence_array_test.shape)\n",
    "print('aug_state_array_test: ',aug_state_array_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxQTNjpblAMN"
   },
   "source": [
    "## Initiate Agent & Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 金融交易環境for資產配置\n",
    "class StockPortfolioEnv:  \n",
    "    \n",
    "    # 初始化參數由env_args傳入\n",
    "    def __init__(self, \n",
    "                 price_array, #各公司的股價(調整後收盤價)\n",
    "                 tech_array, #技術指標陣列\n",
    "                 aug_state_array, #其他的state(embedding / 時間資訊 / 資產資訊)\n",
    "                 env_name, #環境名稱\n",
    "                 lookback, #window size(每次交易看過去幾天) \n",
    "                ):\n",
    "        \n",
    "        initial_capital = 100000\n",
    "        \n",
    "        self.lookback = lookback  # 預設看過去10天\n",
    "        self.initial_total_asset = initial_capital # 初始總資產(股票+現金)\n",
    "        self.initial_cash = initial_capital #初始現金\n",
    "        \n",
    "        self.trans_cost = 0.01 #交易手續費(買賣都一樣)\n",
    "        self.buy_cost_pct = self.trans_cost # buy手續費\n",
    "        self.sell_cost_pct = self.trans_cost # sell手續費\n",
    "        self.gamma = 1 # reward遞減係數\n",
    "        \n",
    "        # 載入放入state的陣列\n",
    "        self.price_array = price_array \n",
    "        self.tech_array = tech_array  \n",
    "        self.aug_state_array = aug_state_array        \n",
    "        \n",
    "        # 價格轉成daily return \n",
    "        self.price_return = pd.DataFrame(self.price_array).pct_change(1).fillna(0).values\n",
    "\n",
    "        \n",
    "        self.stock_num = self.price_array.shape[1] #有幾隻股票要交易\n",
    "        self.max_step =  self.price_array.shape[0] - lookback -1 #每個episode最多走幾步(期初走到最後一天)\n",
    "        self.env_num = 1 #有幾個環境(預設為1)\n",
    "        \n",
    "        # 將環境初始化\n",
    "        self.time = lookback-1 #現在的時間點\n",
    "        self.cash = self.initial_cash\n",
    "        self.current_price = self.price_array[self.time]\n",
    "        self.current_tech = self.tech_array[self.time] if self.tech_array.shape[0]>0 else self.tech_array\n",
    "        self.current_aug_state = self.aug_state_array[self.time] if self.aug_state_array.shape[0]>0 else self.aug_state_array\n",
    "        self.portfolio = np.zeros(self.stock_num, dtype=np.float32) #現在手上的股票部位\n",
    "        \n",
    "        # 紀錄訓練的結果\n",
    "        self.history = {'cumu_return':[],'action':[]}\n",
    "\n",
    "        # 紀錄現有資產及報酬率\n",
    "        self.total_asset = self.cash + (self.portfolio * self.price_array[self.time]).sum()\n",
    "        self.episode_return = 0.0  \n",
    "        self.gamma_return = 0.0\n",
    "        \n",
    "\n",
    "        '''env information'''\n",
    "        self.env_name = env_name\n",
    "        # self.state_dim = self.price_return.shape[1]*lookback \n",
    "        self.state_dim = (self.price_array.shape[1] + self.tech_array.shape[1])*lookback\n",
    "        self.action_dim = self.price_return.shape[1]+1 #加一維cash\n",
    "        self.mid_dim = 16 #過完CNN每家公司的embedding長度  \n",
    "        self.aug_state_dim = 10\n",
    "        #self.current_working_dir = current_working_dir\n",
    "        \n",
    "\n",
    "        self.if_discrete = False\n",
    "        self.target_return = 10\n",
    "        self.total_cumulative_return = []\n",
    "        \n",
    "    # softmax\n",
    "    def action_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator/denominator\n",
    "        \n",
    "        return softmax_output\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        self.time = self.lookback-1\n",
    "        self.current_price = self.price_array[self.time]\n",
    "        self.current_tech = self.tech_array[self.time] if self.tech_array.shape[0]>0 else self.tech_array\n",
    "        self.current_aug_state = self.aug_state_array[self.time] if self.aug_state_array.shape[0]>0 else self.aug_state_array\n",
    "        self.cash = self.initial_cash  # reset()\n",
    "        self.portfolio = np.zeros(self.stock_num, dtype=np.float32) # 持有股數\n",
    "        self.total_asset = self.cash + np.sum(self.portfolio * self.price_array[self.time]) # 總資產價值\n",
    "        self.history = {'cumu_return':[],'action':[],'total_asset':[],'episode return':[]}\n",
    "        self.episode_return = 0.0\n",
    "        self.gamma_return = 0.0\n",
    "        state  = self.get_state()\n",
    "        \n",
    "        return state\n",
    "\n",
    "    \n",
    "    def step(self, actions) -> (np.ndarray, float, bool, None):\n",
    "        self.time += 1\n",
    "        #print('time:',self.time)\n",
    "        \"\"\"transaction\"\"\"\n",
    "        # 隔一天的weight，包含股票及現金的持有比例\n",
    "        action = self.action_normalization(actions)\n",
    "        action = action.reshape(-1)\n",
    "        \n",
    "        # 新的持有股數：現在的weight*前一天總資產價值/股價(無條件捨去)\n",
    "        new_portfolio = np.floor(action[:-1]*self.total_asset/self.price_array[self.time-1])\n",
    "        \n",
    "        # 前一天配置股票剩餘資金納入手上現金部位\n",
    "        self.cash = self.total_asset - sum(new_portfolio*self.price_array[self.time-1])\n",
    "        \n",
    "        # 計算手續費\n",
    "        portfolio_change = np.sum((new_portfolio-self.portfolio)*self.price_array[self.time-1])\n",
    "        trans_cost = portfolio_change*self.trans_cost\n",
    "        self.cash-=trans_cost\n",
    "        \n",
    "        # 計算新的資產價值\n",
    "        new_total_asset = np.sum(new_portfolio*self.price_array[self.time])+self.cash\n",
    "        #print('cash',self.cash)\n",
    "        \n",
    "        # 計算報酬率\n",
    "        portfolio_return = new_total_asset/self.total_asset\n",
    "        self.cumu_return = new_total_asset/self.initial_total_asset\n",
    "        reward = (portfolio_return-1)*100\n",
    "    \n",
    "        #更新資產狀態\n",
    "        self.total_asset = new_total_asset\n",
    "        self.portfolio = new_portfolio\n",
    "        \n",
    "        self.gamma_return = self.gamma_return * self.gamma + reward \n",
    "        self.cumu_return = self.total_asset / self.initial_cash\n",
    "        \n",
    "        self.history['cumu_return'].append(self.cumu_return)\n",
    "        self.history['action'].append(action)\n",
    "        self.history['total_asset'].append(self.total_asset)\n",
    "        # print( self.history['cumu_return'])\n",
    "                \n",
    "        \"\"\"update time\"\"\"\n",
    "        done = self.time == self.max_step+self.lookback\n",
    "        state = self.get_state()\n",
    "        self.episode_return = self.total_asset / self.initial_total_asset\n",
    "        if done:\n",
    "            #print('self.max_step',self.max_step)\n",
    "            reward = self.gamma_return\n",
    "            self.episode_return = self.total_asset / self.initial_total_asset\n",
    "            \n",
    "            ''' \n",
    "            # 畫圖\n",
    "            plt.plot(self.history['cumu_return'])\n",
    "            plt.savefig('./train_history/cumulative_return/cumulative_plot'+datetime.now().strftime('%Y-%m-%d %H:%M:%S')+'.png')\n",
    "            plt.close()\n",
    "            '''\n",
    "            \n",
    "            # 每個episode交易紀錄存檔\n",
    "            pd.DataFrame(self.history['cumu_return']).to_csv('./train_history_sentiment/cumulative_return/cumu_return'\\\n",
    "                                                             +datetime.now().strftime('%Y-%m-%d %H:%M:%S')+'.csv')\n",
    "            pd.DataFrame(self.history['action']).to_csv('./train_history_sentiment/action/action'\\\n",
    "                                                             +datetime.now().strftime('%Y-%m-%d %H:%M:%S')+'.csv')\n",
    "        return state, reward, done, None\n",
    "\n",
    "    def get_state(self):\n",
    "        # 從現在時間往前取n天(lookback)\n",
    "        state = self.price_return[self.time-self.lookback+1:self.time+1].reshape(-1)*100 #flatten\n",
    "        if self.aug_state_array.shape[0]!=0: #如果有aug_state的話\n",
    "\n",
    "            state = np.concatenate((state,self.aug_state_array[self.time]))\n",
    "\n",
    "        if self.tech_array.shape[0]!=0: #如果有tech_array的話\n",
    "            for i in range(self.lookback):\n",
    "                tech_i = self.tech_array[self.time-i]\n",
    "                normalized_tech_i = tech_i * 2 ** -15\n",
    "                state = np.hstack((state, normalized_tech_i)).astype(np.float32)\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空資料夾\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists('./train_history_sentiment'):\n",
    "    shutil.rmtree('./train_history_sentiment')\n",
    "\n",
    "if not os.path.exists(\"./\" + 'train_history_sentiment'):\n",
    "    os.makedirs(\"./\" + 'train_history_sentiment')\n",
    "if not os.path.exists(\"./\" + 'train_history_sentiment/cumulative_return'):\n",
    "    os.makedirs(\"./\" + 'train_history_sentiment/cumulative_return')\n",
    "if not os.path.exists(\"./\" + 'train_history_sentiment/action'):\n",
    "    os.makedirs(\"./\" + 'train_history_sentiment/action')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate RL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/.conda/envs/finrl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Arguments Remove cwd: ./sentimnet_portfolio_allocation_PPO_0\n",
      "cwd: ./sentimnet_portfolio_allocation_PPO_0\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
      "0  4.45e+03    1.40 |\n",
      "0  4.45e+03    1.40 |    1.40    0.0    493     0 |\n",
      "0  1.38e+05    2.68 |\n",
      "0  1.38e+05    2.68 |    2.68    0.0    493     0 |\n",
      "0  2.71e+05    4.59 |\n",
      "0  2.71e+05    4.59 |    4.59    0.0    493     0 |\n",
      "0  4.00e+05    6.13 |\n",
      "0  4.00e+05    6.13 |    6.13    0.0    493     0 |\n",
      "0  5.11e+05    7.69 |\n",
      "0  5.11e+05    7.69 |    7.69    0.0    493     0 |\n",
      "0  6.22e+05    7.72 |\n",
      "0  6.22e+05    7.72 |    7.72    0.0    493     0 |\n",
      "0  7.38e+05    8.40 |\n",
      "0  7.38e+05    8.40 |    8.40    0.0    493     0 |\n",
      "0  8.49e+05    9.12 |\n",
      "0  8.49e+05    9.12 |    9.12    0.0    493     0 |\n",
      "0  9.56e+05    8.90 |\n",
      "0  9.56e+05    8.90 |    8.90    0.0    493     0 |\n",
      "0  1.03e+06    9.97 |\n",
      "0  1.03e+06    9.97 |    9.97    0.0    493     0 |\n",
      "0  1.08e+06   10.43 |\n",
      "0  1.08e+06   10.43 |   10.43    0.0    493     0 |\n",
      "0  1.12e+06   11.21 |\n",
      "0  1.12e+06   11.21 |   11.21    0.0    493     0 |\n",
      "0  1.20e+06   12.66 |\n",
      "0  1.20e+06   12.66 |   12.66    0.0    493     0 |\n",
      "0  1.32e+06   12.74 |\n",
      "0  1.32e+06   12.74 |   12.74    0.0    493     0 |\n",
      "0  1.43e+06   13.68 |\n",
      "0  1.43e+06   13.68 |   13.68    0.0    493     0 |\n",
      "0  1.46e+06   13.63 |\n",
      "0  1.46e+06   13.63 |   13.63    0.0    493     0 |\n",
      "0  1.51e+06   14.65 |\n",
      "0  1.51e+06   14.65 |   14.65    0.0    493     0 |\n",
      "0  1.56e+06   14.94 |\n",
      "0  1.56e+06   14.94 |   14.94    0.0    493     0 |\n",
      "0  1.60e+06   14.85 |\n",
      "0  1.60e+06   14.85 |   14.85    0.0    493     0 |\n"
     ]
    }
   ],
   "source": [
    "'''import你要跑的演算法'''\n",
    "from elegantrl.agents.AgentPPO import AgentPPO \n",
    "from elegantrl.train.config import Arguments\n",
    "from elegantrl.train.run import train_and_evaluate,test_agent\n",
    "\n",
    "env_func = StockPortfolioEnv\n",
    "env_args = {\n",
    "    'env_name':'sentimnet_portfolio_allocation',\n",
    "    'if_discrete' : False,\n",
    "    'target_return' : 42,\n",
    "    'lookback':10,\n",
    "    'env_num':1,\n",
    "    'max_step':1000,\n",
    "    'state_dim':810,#price+tech+sentiment\n",
    "    'action_dim':11,\n",
    "}\n",
    "\n",
    "train_env_args = env_args.copy()\n",
    "test_env_args = env_args.copy()\n",
    "train_env_args.update({\n",
    "    'price_array' : price_array_train,\n",
    "    'tech_array':tech_array_train,\n",
    "    'turbulence_array':turbulence_array_train,\n",
    "    'aug_state_array' : aug_state_array_train\n",
    "})\n",
    "\n",
    "test_env_args.update({\n",
    "    'price_array' : price_array_test,\n",
    "    'tech_array':tech_array_test,\n",
    "    'turbulence_array':turbulence_array_test,\n",
    "    'aug_state_array' : aug_state_array_test})\n",
    "\n",
    "train_args = Arguments(AgentPPO, env_func=env_func, env_args=train_env_args)\n",
    "test_args = Arguments(AgentPPO, env_func=env_func, env_args=test_env_args)\n",
    "\n",
    "\n",
    "train_and_evaluate(train_args)\n",
    "print('=====testing=====')\n",
    "# test_agent(test_args)\n",
    "\n",
    "\n",
    "'''\n",
    "TODO: add baseline\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "TODO: print testing result\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args.net_dim,train_args.state_dim, train_args.action_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "name = []\n",
    "cumu_return = []\n",
    "count = 0\n",
    "for root,_,files in os.walk('./train_history_sentiment/cumulative_return'):\n",
    "    for i in files:\n",
    "        if i.endswith('csv') and 'checkpoint' not in i:\n",
    "            name.append(i)   \n",
    "            \n",
    "name.sort()\n",
    "for i in name:\n",
    "    count+=1\n",
    "    tmp = pd.read_csv(os.path.join('./train_history_sentiment/cumulative_return',i))\n",
    "    cumu_return.append(tmp['0'].values[-1])\n",
    "            \n",
    "print('total episode:',count)\n",
    "ma = pd.DataFrame(cumu_return).rolling(500).mean()\n",
    "plt.title('episode cumulative return in training period')\n",
    "plt.ylabel('cumu return')\n",
    "plt.xlabel('number of episode')\n",
    "plt.plot(cumu_return)\n",
    "plt.plot(ma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent(test_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFO42LcomPUT",
    "tags": []
   },
   "source": [
    "# Plot result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training action v.s. sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = './train_history_sentiment/action/'\n",
    "action =sorted( os.listdir(root))[-2]\n",
    "print(action)\n",
    "df = pd.read_csv(os.path.join(root,action))\n",
    "price_array = price_array_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. df是每個時間點的action(portfolio weight)\n",
    "2. price_array是每家公司的股價\n",
    "3. ticker list是每間公司的代號(只是用來顯示在圖片的title而已)\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "for num,name in enumerate(ticker_list):\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "    ax2 = ax1.twinx() \n",
    "    score = train_filtered_sentiment_score_df[train_filtered_sentiment_score_df.tic==name]['value']\n",
    "    # fig = plt.figure()\n",
    "    # fig.set_figheight(15)\n",
    "    # fig.set_figwidth(20)\n",
    "    # ax = fig.add_subplot(111)\n",
    "    Y = price_array[11:,num]\n",
    "    X = range(len(Y))\n",
    "    buy_sig = df.iloc[:,num+1].diff().fillna(0)>0.1  # 大於10%才有箭頭 \n",
    "    sell_sig = df.iloc[:,num+1].diff().fillna(0)<-0.1\n",
    "    ax1.plot(X,Y,label='Price',c='r')\n",
    "    # print(score[11:].rolling(10).mean())\n",
    "    ax2.plot(X,score[11:].rolling(5).mean(),label='sentiment score')\n",
    "    for i in X:\n",
    "        if buy_sig[i]:\n",
    "            #print('buy')\n",
    "            ax1.annotate(\"\", xy=(i, Y[i]-0.1),xytext=(i, Y[i]-0.3), arrowprops=dict(facecolor=\"g\", alpha=0.5, headlength=4, width=0.1)) \n",
    "        elif sell_sig[i]:\n",
    "            #print('sell')\n",
    "            ax1.annotate(\"\", xy=(i, Y[i]+0.1),xytext=(i, Y[i]+0.3),arrowprops=dict(facecolor=\"r\", alpha=0.5, headlength=4, width=0.1)) \n",
    "    plt.title(name)\n",
    "    ax1.set_xlabel('X-axis')\n",
    "    ax1.set_ylabel('Price')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing action v.s. sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './train_history_sentiment/action/'\n",
    "action = sorted(os.listdir(root))[-1]\n",
    "print(action)\n",
    "df = pd.read_csv(os.path.join(root,action)).iloc[:,1:]\n",
    "price_array = price_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. df是每個時間點的action(portfolio weight)\n",
    "2. price_array是每家公司的股價\n",
    "3. ticker list是每間公司的代號(只是用來顯示在圖片的title而已)\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "for num,name in enumerate(ticker_list):\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "    ax2 = ax1.twinx() \n",
    "    score = test_filtered_sentiment_score_df[train_filtered_sentiment_score_df.tic==name]['value']\n",
    "\n",
    "    Y = price_array[11:,num]\n",
    "    X = range(len(Y))\n",
    "    buy_sig = df.iloc[:,num+1].diff().fillna(0)>0.1  # 大於10%才有箭頭 \n",
    "    sell_sig = df.iloc[:,num+1].diff().fillna(0)<-0.1\n",
    "    ax1.plot(X,Y,label='Price',c='r')\n",
    "    ax2.plot(X,score[11:].rolling(5).mean(),label='sentiment score')\n",
    "    for i in X:\n",
    "        if buy_sig[i]:\n",
    "            #print('buy')\n",
    "            ax1.annotate(\"\", xy=(i, Y[i]-0.1),xytext=(i, Y[i]-0.3), arrowprops=dict(facecolor=\"g\", alpha=0.5, headlength=4, width=0.1)) \n",
    "        elif sell_sig[i]:\n",
    "            #print('sell')\n",
    "            ax1.annotate(\"\", xy=(i, Y[i]+0.1),xytext=(i, Y[i]+0.3),arrowprops=dict(facecolor=\"r\", alpha=0.5, headlength=4, width=0.1)) \n",
    "    plt.title(name)\n",
    "    ax1.set_xlabel('X-axis')\n",
    "    ax1.set_ylabel('Price')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAvxipWFmUe8"
   },
   "source": [
    "### BackTest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(price_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UBAH_return = (price_array_test[-1,:]-price_array_test[10,:])/price_array_test[10,:]\n",
    "print(UBAH_return.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UBAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubah = ((pd.DataFrame(price_array_test).pct_change()*5/6).fillna(0)+1)\n",
    "ubah = ubah.cumprod().mean(axis=1)\n",
    "ubah.to_csv('./train_history_sentiment/UBAH_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(price_array_test,columns=['aapl' 'amt' 'amzn' 'brk-a' 'dis' 'jnj' 'lin' 'mmm' 'nee' 'wmt' 'xom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(price_array_test).pct_change().fillna(0)+1\n",
    "np.mean(np.cumprod(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_array_test[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_array_test[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(price_array_test.shape[0])):\n",
    "    price_array_test[i]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lvrqTro3lhAh",
    "a3Iuv554xYFH",
    "SPEXBcm-uBJo",
    "iidB5E27dfzh"
   ],
   "include_colab_link": true,
   "name": "FinRL_PortfolioAllocation_NeurIPS_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-finrl]",
   "language": "python",
   "name": "conda-env-.conda-finrl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
